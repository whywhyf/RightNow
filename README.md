# report

# RightNow基于物体检测的篮球辅助训练软件

组长：黄渊？

组员：张佳安 叶洋帆 严袁菲 王振超 苏正昊

## 1、项目简介

### 1.1 项目背景

​		在杭州亚运会即将来临的社会大背景下，体育竞技的氛围也逐渐地深入到每个人的生活中。篮球作为一项受欢迎且广泛参与的竞技运动，吸引了大量运动员和篮球爱好者的关注。然而，在实际训练中，篮球运动员常常面临技术分析和动作训练的挑战，需要专业教练的指导和辅助训练。为了更好地满足篮球运动员的训练需求，我们团队开发了一款创新的辅助训练软件，旨在提高篮球运动员的技术水平、优化动作训练，帮助他们能够在单独情况下也能够进行一些简单的篮球训练，并进行一些简单的技术动作分析，达到提升竞技水平、强身健体的效果。

​		我们希望能够借助这一辅助训练软件，为2023年杭州亚洲运动会的成功举办贡献一份技术和科技的力量，迎接杭州地区的篮球运动将迎来全新的发展阶段。同时，我们也期待这款软件能够为更多篮球爱好者带来实质性的训练提升和进步，推动篮球运动持续繁荣发展。



### 1.2 项目意义

​		我们开发的篮球运动员技术分析与动作训练辅助训练软件在杭州即将举行的亚洲运动会背景下具有重要的意义和价值：

1. 提升使用者的篮球水平：作为一项辅助训练工具，该软件将帮助篮球运动员在训练中更加科学、精准地分析和优化技术动作。通过智能技术分析和实时反馈，运动员可以更准确地了解自身训练成果和改进方向，从而提高篮球运动技能水平。
2. 为使用者提供简单的训练：作为一款辅助训练软件，可以为软件的使用者提供两种简单的运球训练模式，通过设置得分的方式为训练过程增加了娱乐性与趣味性，能够在一定程度上加强训练者的基本功底。
3. 提高教练员指导效率：对于教练员而言，软件提供了科学化的技术分析和数据支持，帮助他们更准确地发现运动员存在的问题，制定针对性的训练方案。通过软件的辅助，教练员能够更好地指导和帮助运动员克服技术难题， [test4.pt](test4.pt) 提升整体团队实力。
4. 推动体育科技发展：该项目将体育与科技有机结合，充分发挥深度学习、计算机视觉等技术在篮球运动训练中的应用。借助高科技手段，我们可以提高训练效率，优化训练体验，推动体育科技发展，为中国体育技术水平的提升做出贡献。

​		总体而言，该项目的意义在于将科技与体育相结合，推动篮球运动的智能化和精准化发展，为篮球运动员的进步和亚洲运动会的成功举办提供强有力的支持和帮助。我们相信，通过持续创新和努力，这款辅助训练软件能够为篮球运动的未来发展贡献出一定的价值。



### 1.3 需求分析

​		我们的产品主要面向篮球爱好者与篮球队这两个市场主体，产品通过分析模块与训练模块为用户提供运动过程中的关键数据提取与分析以及相关的篮球训练，帮助个人用户与团队用户更好地认知自己的优势与不足，进一步提升个人的篮球水平。

1. 篮球爱好者

   - 痛点：

     篮球爱好者的运动时间往往较为琐碎，缺少成体系的训练模式以及训练数据整理，导致他们对自己的优势与不足缺少准确认知，对自己篮球水平的变化缺少记录。同时由于缺少成体系的训练模式，导致个人篮球水平提升较慢。

   - 需求：

     1. 记录运动时的数据并提供优势与劣势分析；
     2. 记录篮球水平变化趋势线；
     3. 提供训练模块帮助个体完成篮球相关训练。

   - 解决方案：

     用户只需要用一个手机拍下自己打篮球的视频，将视频提交到我们的产品中之后我们就可以反馈他的运动数据，包括命中率、出手速度与出手角度等，同时我们还会给出篮球热点图，帮助用户了解自己的优势投篮区。除了分析模块以外，我们还提供了训练模块，分为控球训练与触点训练，帮助用户提高自己的篮球水平。

  2. 篮球队

     - 痛点：

       篮球队运动员较多而教练较少，教练无法同时关注多个球员，为所有球员提供指导。

     - 需求：

       1. 记录每个球员的技术指标，为教练提供参考；
       2. 记录球员水平变化趋势线。

     - 解决方案：

       将训练视频传入我们的篮球助手中，得到命中率、出手速度与出手角度等技术指标同时获得每个球员的优势投篮区帮助教练制定球队战略。

篮球助手中的训练模块对专业球员的帮助可能并不大，但依旧可以给球员提供一种训练模式。



### 1.4 可行性分析

1. 近年随着YOLO等跟踪算法的发展与成熟，可以较准确地实现画面中的物体识别与跟踪，为我们的软件提供了开发基础。同时YOLOv8在GitHub上给出了开源代码，可以实现自主的模型训练。
2. MediaPipe框架可以实现对检测目标关键点的识别，可以被应用在软件开发中使用到的手势识别、姿态识别等部分，为训练模式提供支持。
3. 随着篮球运动的普及，篮球训练的需求也越来越大，一个篮球训练辅助软件能够为偌大的篮球爱好者群体提供有效的帮助。



## 2、项目任务与时间安排

### 2.1 设计思路与技术路线

#### 总体设计思路





#### YOLOv8 from ultralytics

- github地址：https://github.com/ultralytics/ultralytics 



- yolov8是一个易用的，适用于中小型项目的用于图像检测的模型库，其检测能力包括
  - 物体检测
  - 图像分割
  - 姿态识别
  - 物体跟踪
  - 物体分类
- 并可以方便地使用自定义训练集，训练具有针对性的模型



- 在此项目中，YOLOv8用于
  - 篮球的检测
  - 篮筐的检测
  - 投篮分析中人体姿态的识别



#### Mediapipe

- github地址：[GitHub - google/mediapipe: Cross-platform, customizable ML solutions for live and streaming media.](https://github.com/google/mediapipe)



- Mediapipe是一个用于构建机器学习管道的框架，用于处理视频、音频等时间序列数据。这个跨平台框架适用于桌面/服务器、Android、iOS和嵌入式设备，如Raspberry Pi和Jetson Nano。MediaPipe Solutions是基于特定的预训练TensorFlow或TFLite模型的开源预构建示例。MediaPipe Solutions构建在框架之上。目前，它提供了16个Solutions。常用的Solutions有
  - 人体姿态检测
  - 手部关键点检测
  - 人脸识别
  - 3D目标检测




- 在此项目中，MediaPipe用于
  - 运球触点训练时的手部跟踪
  - 手势识别



#### PyQt

​	PyQt是一种用于创建图形用户界面(GUI)的Python绑定库。它结合了Python编程语言的简洁性和强大性，以及Qt框架的跨平台能力和丰富的功能集合。PyQt提供了对Qt库的完整访问，包括Qt的各种模块和类。通过PyQt，开发人员可以使用Python语言轻松创建各种功能丰富的GUI应用程序，包括桌面应用程序、移动应用程序和嵌入式系统。以下是我们选用PYQT的理由：

- PyQt有丰富的组件，包括按钮、标签、对话框等，可以用于构建用户友好的界面，在本项目中我们采用按钮来控制界面跳转，用标签来接收画面并呈现；
- PyQt采用事件驱动的编程模型，我们通过连接信号和槽来响应按键操作实现页面跳转；
- PyQt允许在应用程序中使用多线程，以提高性能并避免界面冻结，在本项目中手势识别、视频分析与篮球训练都被封装为线程类，在运行时开启相关线程，避免主线程阻塞。



### 2.2 架构图

![9239d4909fd3097997506cc1472e0b2](C:\Users\HP\AppData\Local\Temp\WeChat Files\9239d4909fd3097997506cc1472e0b2.jpg)

### 2.3 分工

#### 界面设计

严袁菲

#### 投篮分析

张佳安、叶洋帆

#### 运球训练

黄渊、苏正昊

#### 手势（语音）控制

王振超



## 3、项目设计与实现过程

### 3.1 界面设计

- 主界面设计

  - 标题

    我们将“RIGHT NOW”作为项目名称，意思是当用户打开软件的时候，

- 视频界面设计

- 结算界面设计

- 训练模式界面设计



### 3.2 投篮分析

- 模型训练

  - 数据集

    使用roboflow平台用公开数据集（约2500张）和自制数据集（约500张），手动标注并用初代模型辅助标注，创建具有篮球和篮筐数据标注的训练数据集

  - 训练

    使用yolo库进行训练，使用速度最快的yolov8n模型，能够有效识别篮球和篮筐。151代时已有50代无明显进步，停止训练。

  - 模型结果指标

  - ![results](C:\Users\HP\Desktop\things\offterm\court\train\runs\detect\train12\results.png) 

  - | epoch | precision(B) | recall(B) | mAP50(B) | mAP50-95(B) |
    | ----- | ------------ | --------- | -------- | ----------- |
    | 151   | 0.96064      | 0.88955   | 0.93248  | 0.72082     |

    

- 命中与否的判定

  - 记录每一帧篮球和篮筐的位置，若未识别，则保留上一次的位置，根据高度变化，判断是否出手。
  - 识别篮筐的位置，将篮筐及下方锥形区域作为命中判断区，若在此区域检测到篮球，判断该球上一帧位置是否在篮筐之上，若是，则视为命中

- 出手时间、角度的计算

  - 当手腕比肩膀高出一定距离后判定球已经出手，当手腕高于手肘时判定开始投篮，同时判定当手腕高于手肘，但之后又未高出肩膀一定距离的行为为运球，即将出手时间重新置0
    - 当球出手之后，判定已经出手，记录此时的时间以及出手的角度
    - 在每次出手后，计算合计的平均出手时间和角度

- 出手点位图的记录

  - 通过确定球场的固定点在画面中的位置，对画面进行仿射变换，结合出手、命中判断（时间点）和姿态识别（地点），得到画有出手位置，命中与否的出手点位图
  - 由于无法自动识别球场的固定点，为了对任意视频都能进行分析，需要在视频开始前手动确定球场的四个点位。按照左上，左下，右下，右上的顺序点击确定，然后再次点击任意处启动分析![微信截图_20230720095048](C:\Users\HP\Desktop\things\offterm\court\ba\微信截图_20230720095048.png)
  - O代表命中，+代表未命中
  - ![2023-07-20 (3)](C:\Users\HP\OneDrive\图片\屏幕快照\2023-07-20 (3).png)



### 3.3 运球训练

+ 模型训练

  + ![326cd6bb86b175b29b1c11a63abaf7a](C:\Users\HP\AppData\Local\Temp\WeChat Files\326cd6bb86b175b29b1c11a63abaf7a.png)

  + | epoch | precision(B) | recall(B) | mAP50(B) | mAP50-95(B) |
    | ----- | ------------ | --------- | -------- | ----------- |
    | 99    | 0.72225      | 0.78812   | 0.80095  | 0.54218     |

    

+ 生成得分点

  + 在实时显示屏幕中的x方向上选取左右两侧两个中心位置，利用高斯分布围绕这两个中心位置生成得分点的x坐标；在y方向上设置坐标位置不高于屏幕高度的一半、不低于屏幕高度的0.2，由此生成了一个在x方向上围绕左右两个x中心坐标、y方向上在一个高度范围内随机生成的坐标点。
  + 为了达到更好的训练效果，坐标点的生成应该在左右两侧轮流生成，使用一个generateFlag，当其值为True时，得分点生成位置位于屏幕右侧，为False时得分点生成位置位于屏幕左侧。
  + 为了增强训练的娱乐性与难度，随着运球得到的分数增高，生成得分点的速度也会随之加快。

+ 计算得分

  + 两种模式下，当球/手距离得分点的距离小于一定的数值时，就判定得分。
  + 在用手触点得分的模式下，位于屏幕左侧的点必须使用左手触点、屏幕右侧的点必须使用右手触点才能判定得分。



### 3.4 手势识别

* 获取手势图像
  * 采用 MediaPipe 的手势检测以及opencv开启电脑摄像头，获取实时手势图像，并识别出人体手部各识别采样点的位置。
* 识别手势
  * 依据上述 MediaPipe 的手势检测得到的手势识别图像，单独分析手指的各个关节，以各关节相对位置作为识别的判断依据。这里我们需要两种手势进行对软件功能的选择，我们选择了手作出“1”和“2”代表两个不同的值，其中“1”有三个手指弯曲，“2”有两个手指弯曲（除去大拇指），将手指弯曲判断依据设定为第二个关节高于指尖。
* 返回不同手势所对应的值
  * 添加防抖功能。当未出现上述两个手势时，不返回值；当出现其中一个手势且此手势持续了若干时间段（1s），返回该手势所代表的值；若在此时间段中手势改变，重新计时，以保证返回的数据稳定。



## 4、项目难点与解决方案

### 4.1 界面设计

- 线程设计

  为了避免主线程阻塞，我们将手势识别、视频分析、控球训练与触点训练均封装为线程类，在需要时开启相应线程并获得所需参数。与各线程的接口设计是界面设计后期的主要内容：

  手势识别线程：开启后传回识别到的手势；

  视频分析线程：开启后每帧传回视频画面、点图与五个分析数据；结束时传回结束信号；

  控球训练线程：开启后返回实时图像以及得分点。

- 视频信号接入

  为了接收视频分析线程返回的视频信号，我们原先采用了 PYQT 中的多媒体控件，然而由于多媒体控件无法实现视频帧控制，因此我们最后选择了 Lable 控件作为画面的接收载体。视频分析线程在分析完每帧画面后返回该画面信号并最终呈现在标签控件上。

- 线程结束信号传入

  线程类的开启有固定的方法start()，但缺少适合该项目的结束方法，因此我们在线程中定义了stop()方法，通过控制类全局变量来跳出run()函数中的while循环，实现线程的终止，并确保下次线程可正常开启。

- 按键与手势判断结合

  为了实现多方式操作，我们设计了按键操作与手势控制，但也因此带来了按键操作与手势控制的配合问题。在每一个选择页面按键操作与手势控制同时启动，若之后是通过按键操作完成页面跳转则在跳转后关闭该次的手势识别，并根据新页面的要求开启或关闭手势控制。



### 4.2 投篮分析

- 模型训练

  - 难点：项目要求能够识别篮球和篮筐的位置，但yolo自带的模型不包括篮球和篮筐

    解决：在roboflow平台使用公开数据集和自己录制的数据集，进行篮球和篮筐的数据标志，再使用该自定义数据集训练模型

- 命中与否的判定

  - 判断命中

    难点：由于数据集和模型能力的限制，球在篮筐和篮板前难以进行识别，无法直接获取球经过篮筐时的位置

    解决：首先识别球筐和篮球的位置，并记录每帧篮球的位置，当篮球出现在篮筐中或者篮筐下方的锥形区域时，判断该球的上一帧的位置，如果在篮筐的上方，则视为命中。

    难点：当篮球以较小角度投入篮筐，容易误判为非命中，

    解决：将篮筐下的竖直识别区域改为锥形识别区域

  - 判定出手

    难点：篮球和人体的运动较为复杂，难以判断篮球是否出手

    解决：使用一个flag，每当flag为True并且篮球高于篮筐，视为出手并将flag赋False，当篮球接近地面时，视为出手结束，并将flag赋True等待下一次出手

- 出手时间、角度的计算
  
    - 出手时间计算

      难点：如何通过人体姿态判定篮球是否已经出手

    ​       解决：通过调用yolo8-pose库，当手腕比肩膀高出一定距离后判定球已经出手，当手腕高于手肘时判定开    始投篮

    ​       难点：单纯调用人体姿态判定手腕高于手肘时为开始投篮容易错误判定，从而影响出手时间的计算

    解决：判定当手腕高于手肘，但之后又未高出肩膀一定距离的行为为运球，即将出手时间重新置0
    
    - 出手角度计算

    ​       难点：人体出手角度时刻变化，难以判定恰好出手时的角度

    ​       解决：通过设置标签位，当恰好判定出手的那一刻记录出手，读取此时的角度信息，并存入数组，每有一个新的数据读入时，通过取平均，计算平均出手角度
    
- 出手点位图的记录
  
      难点：球场边界难以通过模型直接识别，且在单一视角下难以直接获取出手点的信息

    解决：通过手动选取视频中图像的固定点位，对原图像进行仿射变换，从而将点位与一般的球场图进行对应，对于每一个出手点都在出手点位图中有相对应的点进行显示
    
- 难点：当画面中出现多个篮球，容易造成分析的错误

    解决：记录上一帧篮球的位置，在新的一帧中选择所识别篮球中，距离上一帧位置距离最近且不超过一定距离的“篮球”作为认定的篮球，实现简单的物体跟踪



### 4.3 运球训练

- 模型训练

   -通过网上下载的训练集对yolov8模型进行训练，做到能够对篮球的识别

- 判断是否碰到得分点
  
    难点：有时模型会在一帧画面中检测出两个篮球的位置，比如使用者的膝盖或头。
  
    解决：对每一帧画面，规定只能最大检测出一个物体，且设置一个置信度门槛，来获得较高置信度的被检测物体

+ 随机生成的得分点
  + 难点：在限定范围内采用 randint 的方法随机生成得分点位坐标会导致得分点出现位置过于分散，且得分点若完全随机出现，则可能出现得分点单独出现在某侧或者角落位置，难以达到有效训练的效果。
  + 解决：在实时屏幕上确定左右两侧的中心点，利用高斯分布的方法生成随机得分点，使得分点多集中于左右两中心点周围，以达到较好的训练效果。使用一个 flag，flag 为False时得分点出现在屏幕左侧，为True时出现在屏幕右侧。

+ 触点训练时的手部检测
  + 难点：若采用 MediaPipe 的手势检测，在运球人超出摄像头一定距离之后，便无法精确地定位到手部。
  + 解决：采用 MediaPipe Solutions 中的人体姿态识别，在较远的距离仍然可以较为准确地检测到人体手部的四个点并实现跟踪。



### 4.4 手势识别

* 获取手势图像并识别手势
  * 难点：具体手势识别准确度不佳，对于初始选取的一些手势识别准确率不高。
  * 解决：采用 MediaPipe 的手势检测，单独分析手指的各个关节，以各关节相对位置作为识别的判断依据。这里我们需要两种手势进行对软件功能的选择，我们选择了手作出“1”和“2”代表两个不同的值，其中“1”有三个手指弯曲，“2”有两个手指弯曲（除去大拇指），将手指弯曲判断依据设定为第二个关节高于指尖。这样的设置使得手势识别的准确度较高。
* 获取手势识别结果并返回数据
  * 难点：实时手势识别较为灵敏，返回的数据可能会有些许波动导致识别结果错误。
  * 解决：添加防抖功能。当未出现上述两个手势时，不返回值；当出现其中一个手势且此手势持续了若干时间段（1s），返回该手势所代表的值；若在此时间段中手势改变，重新计时，以保证返回的数据稳定。



## 5、讨论与总结
